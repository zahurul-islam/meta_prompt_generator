# Meta Prompt Generator

A system that generates high-quality prompts for various data extraction tasks, streamlining the process of creating effective prompts for LLMs.

## Overview

The Meta Prompt Generator is designed to create custom prompts for extracting structured data from various document types, including:
- Invoices
- Support tickets
- Legal documents
- Emails
- And more...

The system takes a simple request from the user and generates a comprehensive, well-structured prompt that can be used with any LLM to extract the specified data.

## Features

- **Simple Gradio Interface**: Describe what data you need to extract in plain English
- **Specialized for Data Extraction**: Optimized for creating prompts that extract structured data
- **JSON Output Format**: Generates prompts that produce clean, structured JSON output
- **Edge Case Handling**: Includes instructions for handling missing or ambiguous data
- **Multiple LLM Support**: Choose from several model options in the UI
- **Robust Fallback System**: Works even when API connections fail
- **Template-Based Generation**: Uses specialized templates when needed

## Components

The system consists of two main components:

1. **Meta Prompt Generator**: Creates extraction prompts based on user requests
2. **Image Data Extractor**: Uses the generated prompts to extract data from images

### Meta Prompt Generator

Generates high-quality prompts for data extraction tasks based on a simple description. The prompts are designed to be used with any LLM to extract structured data from text documents.

### Image Data Extractor

A companion tool that uses the prompts generated by the Meta Prompt Generator to extract data directly from images using vision-capable LLMs.

## Getting Started

### Prerequisites

- Python 3.8+ 
- Docker (optional, for containerized deployment)
- OpenRouter API key (provided in the configuration or use your own)

### Running with Docker

1. Clone the repository:
   ```
   git clone git@github.com:zahurul-islam/meta_prompt_generator.git
   cd meta_prompt_generator
   ```

2. Start the application:
   ```
   docker-compose up
   ```

3. Access the Meta Prompt Generator UI at http://localhost:7860

### Running Locally

1. Use the start script (recommended):
   ```
   ./start.sh
   ```

2. Or manually:
   ```
   # Install dependencies
   pip install -r requirements.txt
   
   # Run the Meta Prompt Generator
   python -m src.gradio_ui
   
   # Or run the Image Data Extractor
   python -m src.image_extractor
   ```

3. Access the interfaces:
   - Meta Prompt Generator: http://localhost:7860
   - Image Data Extractor: http://localhost:7861 (or as indicated in the console)

## Usage

### Meta Prompt Generator

1. Access the Gradio UI at http://localhost:7860
2. Enter a description of the data extraction task (e.g., "Extract total gross, total net, business name, and items from invoice")
3. Adjust the temperature slider (lower for more precise prompts, higher for more creative prompts)
4. Select a model from the dropdown menu (try different models if one fails)
5. Click "Generate Prompt"
6. Copy the generated prompt and use it with your preferred LLM by replacing `{file_content}` with your document text

### Image Data Extractor

1. Access the Gradio UI at http://localhost:7861 (or as indicated in the console)
2. Upload an image (invoice, receipt, business card, document with tables, etc.)
3. Describe what data you want to extract from the image
4. Select a vision-capable LLM from the dropdown
5. Adjust the temperature slider if needed
6. Click "Extract Data"
7. View the generated prompt and extracted data

## Example Usage

### Meta Prompt Generator

**Input:**
"Prompt that extracts total gross, total net, business name and a list of items including product name and price data as a JSON structure"

**Generated Prompt (Example):**
```
You are a data extraction assistant. Your task is to carefully analyze the invoice provided in {file_content} and extract the following information in a structured JSON format:

1. Business Information:
   - Business name

2. Financial Details:
   - Total gross amount
   - Total net amount

3. Items:
   - For each item on the invoice, extract:
     - Product name
     - Price

Format your response as a JSON object with the following structure:

{
  "business_name": "Example Business Ltd",
  "total_gross": 120.00,
  "total_net": 100.00,
  "items": [
    {
      "product_name": "Product A",
      "price": 50.00
    },
    {
      "product_name": "Product B",
      "price": 70.00
    }
  ]
}

Guidelines:
1. If certain information is not present in the invoice, use null for that field.
2. Convert all monetary values to numbers (not strings).
3. Extract the data exactly as it appears without making assumptions.
4. Only include the JSON in your response, with no additional explanation.
```

### Image Data Extractor

**Input:**
- Image: [Invoice image]
- Task: "Extract invoice number, date, vendor name, and total amount"
- Model: Claude 3 Sonnet

**Output (Example):**
```json
{
  "invoice_number": "INV-12345",
  "date": "2023-05-15",
  "vendor_name": "TechSupplies Inc.",
  "total_amount": 1250.75
}
```

## Project Structure

```
meta_prompt/
├── docker/                   # Docker configuration
│   └── Dockerfile            # Dockerfile for the application
├── docker-compose.yml        # Docker Compose configuration
├── requirements.txt          # Python dependencies
├── scripts/                  # Utility scripts
│   ├── run_api.sh            # Script to run the API (optional)
│   ├── run_gradio.sh         # Script to run the Gradio UI
│   ├── run_image_extractor.sh # Script to run the Image Extractor
│   ├── run_tests.sh          # Script to run tests
│   ├── sample_usage.py       # Example usage script
│   └── setup.sh              # Setup script
├── src/                      # Python source code
│   ├── __init__.py           # Package initialization
│   ├── api.py                # FastAPI server (optional API)
│   ├── config.py             # Configuration settings
│   ├── gradio_ui.py          # Gradio UI for Meta Prompt Generator
│   ├── image_extractor.py    # Image Data Extractor
│   ├── llm_client.py         # LLM API client
│   ├── main.py               # Command-line interface
│   └── prompt_generator.py   # Core prompt generation logic
├── templates/                # Prompt templates
│   ├── email_template.txt    # Template for email extraction
│   ├── invoice_template.txt  # Template for invoice extraction
│   └── legal_template.txt    # Template for legal document extraction
└── tests/                    # Test suite
    ├── test_api.py           # API tests
    └── test_prompt_generator.py  # Generator tests
```

## Robust Error Handling

Both tools include several fallback mechanisms to ensure they work even when API connections fail:

1. **Multiple Models**: If the primary model fails, the system tries alternative models
2. **Template-Based Generation**: If all API calls fail, the system uses pre-defined templates
3. **Generic Fallback**: For unknown document types, a generic extraction prompt is generated

## Configuration

The system can be configured using environment variables:

- `OPENROUTER_API_KEY`: Your OpenRouter API key
- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR)

Create a `.env` file based on the provided `.env.example` file to set these variables.

## Evaluation Strategy

For details on how the system is evaluated and improved, see [EVALUATION.md](EVALUATION.md).

## Troubleshooting

If you encounter any issues, please refer to the [TROUBLESHOOTING.md](TROUBLESHOOTING.md) guide for solutions to common problems, including:

- API connection errors
- Docker permission issues
- Model availability issues
- Fallback mechanisms

## Development

### Adding New Templates

To add support for a new document type:

1. Create a new template file in the `templates/` directory
2. Follow the existing template structure, ensuring it includes:
   - Clear extraction instructions
   - JSON output format guidance
   - Edge case handling

### Running Tests

Run the test suite with:

```
./scripts/run_tests.sh
```

## License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details.
